## Entropy

Shannon entropy is a value or a measure that describes the amount of incertity, "surprise" about a given variable

-maximum is 50%

- high entropy means that the dataset has a lot of variability

- Low entropy means that most of the values of the dataset repeat (and therefore are redundant)



